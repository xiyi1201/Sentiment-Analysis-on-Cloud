# Sentiment-Analysis-in-Cloud
The primary goal of this project is to develop a real-time sentiment analysis system that evaluates the sentiment of customer reviews on Amazon. 

## Table of Contents
- [Project Description](#project-description)
- [Dataset Overview](#dataset-overview)
- [Implemented Models and Results](#implemented-models-and-results)
- [Contributors](#contributors)

## Project Description
The real time system aims to classify each review as positive, neutral, or negative, providing immediate feedback to both sellers and buyers. The analysis will help sellers improve their products and services and give prospective buyers insights into product quality and customer satisfaction.

## [Dataset Overview](https://www.kaggle.com/datasets/snap/amazon-fine-food-reviews)
The dataset spans reviews collected from October 1999 to October 2012, encompassing a total of 568,454 reviews. These reviews were contributed by 256,059 unique users and cover 74,258 distinct products. Among these users, 260 have provided more than 50 reviews each. This rich dataset forms the foundation for deploying a sentiment analysis model to the cloud, allowing us to analyze user sentiments across a broad range of products over an extensive time period.

## Implemented Models and Results
Repository Structure

- **config/**: Contains configuration files necessary to download processed data from the S3 bucket and upload model artifacts back to S3. The `config.yaml` file connects to `app.py`, `pipeline.py`, and `analysis.py`.

- **models/**: Contains `.h5` model files of CNN, LSTM, and SNN models trained by `nn_modeling.py`. Due to their large size, the models are not uploaded to GitHub. Only a screenshot of the model folder is shown.
  - `cnn_model.h5`
  - `lstm_model.h5`
  - `snn_model.h5`
  - `tokenizer.pkl`

- **plots/**: Contains output plots generated by `analysis.py`, including distribution plots of the scores and wordcloud bigram and donut graphs.

- **src/**: Contains the Python scripts. The `glove.txt` file has been deleted because it exceeds 50MB. The `pipeline.py` script runs `analysis.py` and uploads models to S3. The `app.py` script runs separately for inference showcase on the Streamlit website.

- **dockerfile-inference/**: Dockerfile to run `app.py` and showcase a real-time analysis web application example.

- **dockerfile-pipeline/**: Dockerfile to run exploratory data analysis and upload models to S3.

## Web App
![web1](https://github.com/MSIA/Cloud_Proj_Group6/assets/60202992/76092b27-3c03-4108-92af-7ad551757486)
![web2](https://github.com/MSIA/Cloud_Proj_Group6/assets/60202992/a025c300-58bb-4dfa-a9b7-741e43fa37ad)
![web3](https://github.com/MSIA/Cloud_Proj_Group6/assets/60202992/bbbc029c-a5dd-4474-a7a4-cc20b98fdb7b)


## Contributors
- Yumin Zhang
- Xiyi Lin
- Stella Wang
- Yan Wang
- Grace Xie
